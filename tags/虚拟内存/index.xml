<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>虚拟内存 on Jialong&#39;s Blog</title>
    <link>https://eternityqjl.top/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</link>
    <description>Recent content in 虚拟内存 on Jialong&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>2019-2021 By Jialong</copyright>
    <lastBuildDate>Tue, 04 Jan 2022 14:59:16 +0800</lastBuildDate><atom:link href="https://eternityqjl.top/tags/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Csapp：9.虚拟内存</title>
      <link>https://eternityqjl.top/posts/csapp-9-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</link>
      <pubDate>Tue, 04 Jan 2022 14:59:16 +0800</pubDate>
      
      <guid>https://eternityqjl.top/posts/csapp-9-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/</guid>
      <description>物理和虚拟寻址 物理地址PA、虚拟地址VA、内存管理单元MMU（利用存放在主存中的查询表来动态地翻译虚拟地址，该表的内容由操作系统管理）。
地址空间 非负整数地址的有序集合。
目前x86使用39位物理地址空间、49位虚拟地址空间。
虚拟内存作为缓存的工具 VM系统通过将虚拟内存分割为大小为$P=2^p$字节的虚拟页来处理，同样地，物理内存也被分割为大小为P的物理页（页帧）。
任意时刻，虚拟页面的集合都分为三个不相交的子集：
 未分配的 缓存的 未缓存的  DRAM缓存的组织结构 使用术语SRAM缓存来表示位于CPU和主存之间的L1、L2和L3高速缓存；用术语DRAM缓存表示虚拟内存系统的缓存，它在主存中缓存虚拟页。
在存储层次结构中，DRAM缓存的位置对它的组织结构有很大的影响。DRAM比SRAM慢大约10倍，磁盘比DRAM慢大约100000倍。DRAM缓存的不命中（缺页）比SRAM缓存的不命中要昂贵的多。
与硬件对SRAM缓存相比，操作系统对DRAM缓存使用了更复杂精密的替换算法。对磁盘的访问时间很长，DRAM缓存总是使用写回，而不是直写。
页表 虚拟内存系统必须有方法判断一个虚拟页是否缓存在DRAM中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到DRAM中，替换这个牺牲页。
页表就是一个页表条目（PET）的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE。假设每个PTE由一个有效位和一个n位地址字段组成的。有效位表明该虚拟页当前是否被缓存在DRAM中。
页命中 页面缓存在DRAM缓存中。
缺页 DRAM缓存不命中称为缺页。
在磁盘和内存之间传送页的活动叫作交换或页面调度。只有当不命中发生时，才换入页面，这种策略称为按需页面调度。
所有现代系统都采用按需页面调度的方式。
局部性 局部性原理保证了在任意时刻，程序将趋向于在一个较小的活动页面集合上工作，这个集合称为工作集或常驻集。
只要程序具有良好的时间局部性，虚拟内存系统就能工作得相当好。如果工作集的大小超出了物理内存的大小，程序将产生一种不幸的抖动状态，这时页面将不断地换进换出。
虚拟内存作为内存管理的工具 虚拟内存大大简化了内存管理，并提供了一种自然的保护内存的方法。
操作系统实际上为每个进程提供了一个独立的页表，因而也就是一个独立的虚拟地址空间。
多个虚拟页面可以映射到同一个共享的物理页面上。
VM简化了链接和加载、代码和数据共享，以及应用程序的内存分配。
简化链接 独立的地址空间允许每个进程的内存映射使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。
一个给定的Linux系统上的每个进程都使用类似的内存格式。对于64位地址空间，代码段总是从虚拟地址0x400000开始。数据段跟在代码段后，中间有一段符合要求的对齐空白。栈占用用户地址空间最高的部分，并向下生长。
这样的一致性简化了链接器的设计和实现。允许链接器生成完全链接的可执行文件，这些可执行文件是独立于物理内存中代码和数据的最终位置的。
简化加载 虚拟内存使得很容易向内存中加载可执行文件和共享对象文件。要把目标文件中.text和.data节加载到一个新创建的进程中，Linux加载器为代码和数据段分配虚拟页，把它们标记为无效的（即未被缓存的），将页表条目指向目标文件中适当的位置。加载器从不从磁盘到内存实际复制任何数据。在每个页被初次引用时，要么是CPU取指令时引用的，要么是一条正在执行的指令引用一个内存位置时引用的，虚拟内存系统会按照需要自动地调入数据页。
将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称为内存映射。Linux提供一个称为mmap的系统调用，允许应用程序自己做内存映射。详见后面小节。
简化共享 一般情况下，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程进行共享的。但在另一些情况下，需要进程来共享数据和代码。例如，每个进程必须调用相同的操作系统内核代码，操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本。
简化内存分配 虚拟内存为用户进程提供了一个简单的分配额外内存的机制。当一个运行在用户进程的程序要求额外的堆空间时（调用malloc），操作系统分配一个适当数字大小的连续的虚拟内存页面，并将其映射到物理内存中任意位置的k个任意的物理页面。
虚拟内存作为内存管理的工具 提供独立的地址空间使得区分不同进程的私有内存变得容易。但时地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每个CPU生成一个地址时，地址翻译硬件都会读一个PTE，通过在PTE上添加一些额外的许可位开控制对一个虚拟页面内容的访问十分简单。
例如：
每个PTE添加了三个许可位：
 SUP位：进程是否必须运行在内核（超级用户）模式下才能访问该页 READ位和WRITE位控制对页面的读和写访问  如果一条指令违反了这些许可条件，那么CPU就触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。
地址翻译 页面命中时CPU硬件执行的步骤：
 处理器生成一个虚拟地址，将其传送给MMU MMU生成PTE（Page Table Entry）地址，并从高速缓存/主存请求得到它 高速缓存/主存向MMU返回PTE MMU构造物理地址，并把它传送给高速缓存/主存 高速缓存/主存返回所请求的数据字给处理器  页面命中完全由硬件来处理，与之不同的是，处理缺页要求硬件和操作系统内核协作完成。步骤如下：
 第1-3步：与页面命中时的前三步相同 PTE中的有效位为0，所以MMU触发了一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序。 缺页处理程序确定出物理内存中的牺牲页，如果该页面已经被修改，则把它换出到磁盘。 缺页处理程序页面调入新的页面，并更新内存中的PTE。 缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU将引起缺页的虚拟地址重新发送给MMU。虚拟页面现在缓存在物理内存中，所以就会命中。  结合高速缓存和虚拟内存 在任何既使用高速缓存SRAM又使用虚拟内存的系统中，一般使用物理内存来访问高速缓存。</description>
    </item>
    
  </channel>
</rss>
